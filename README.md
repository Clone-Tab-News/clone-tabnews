# Clone TabNews

Um projeto de exemplo para aprender Next.js, inspirado no TabNews.

## Como rodar o projeto

1. Instale as depend√™ncias:

   ```bash
   npm install
   ```

2. Inicie o servidor de desenvolvimento:

   ```bash
   npm run dev
   ```

3. Acesse [http://localhost:3000](http://localhost:3000) no seu navegador.

## Estrutura inicial

Crie o arquivo `pages/index.js` com o seguinte conte√∫do para exibir a p√°gina inicial:

```javascript
function Home() {
  return (
    <div>
      <h1>Bem-vindo ao Clone TabNews</h1>
      <p>Este √© um projeto de exemplo para aprender Next.js.</p>
    </div>
  );
}

export default Home;
```

Pronto! O servidor estar√° rodando e voc√™ ver√° a mensagem de boas-vindas na p√°gina inicial.

---

## Aula 07: Rela√ß√£o entre Cliente e Servidor

### O que √© Cliente e Servidor?

- **Cliente:** Quem faz uma solicita√ß√£o e espera uma resposta.
- **Servidor:** Quem recebe a solicita√ß√£o e fornece o servi√ßo ou resposta.

#### Exemplos simples

- **Copo de √°gua:** Se algu√©m pede um copo de √°gua, essa pessoa √© o cliente e quem serve √© o servidor. Se voc√™ pede para outra pessoa buscar o copo para entregar, nesse momento voc√™ vira cliente e quem busca vira servidor.
- **Restaurante:** Voc√™ faz o pedido ao gar√ßom (cliente ‚Üí gar√ßom), o gar√ßom pede para a cozinha (gar√ßom ‚Üí cozinha), a cozinha prepara e entrega ao gar√ßom, que traz para voc√™.

---

### Deploy com Vercel

Para publicar seu projeto,

## Aula 09: N√≠veis de Organiza√ß√£o de Tarefas

### N√≠veis de Organiza√ß√£o

#### N√≠vel 1: Ser lembrado individualmente

- Se lembrar do que precisa fazer
- J√° sabe como e o que precisa ser feito, mas precisa ser lembrado para n√£o fazer outra coisa
- Utiliza ferramentas com menor custo de produ√ß√£o (energia) e menor tempo de aquecimento
- **Exemplo:** Anotar tarefas em um papel e deix√°-lo vis√≠vel na mesa de trabalho

#### N√≠vel 2: Ser lembrado em grupo

- Relembrar toda a equipe do que precisa ser feito
- N√£o precisa detalhar muito o que precisa ser feito
- **Exemplo:** Quadros de Kanban

#### N√≠vel 3: Expandir conhecimento

- Desenvolver de forma detalhada o que e como algo deve ser feito
- Documentar processos e compartilhar conhecimento
- **Exemplos:** Trello e GitHub

#### N√≠vel 4: Gerar m√©tricas

- Mensurar a produtividade das pessoas que est√£o trabalhando nas tarefas
- **Exemplo:** Planilhas com informa√ß√µes de tarefas totais, executadas e conclu√≠das
  ![alt text](./class-images/image-1.png)

### Gerenciamento de Projetos

Ao iniciar um novo projeto, n√£o existem apenas as op√ß√µes "Tudo" ou "Nada". H√° uma abordagem intermedi√°ria que envolve dividir o trabalho em partes gerenci√°veis.

Um projeto √© como uma pedra grande que precisa ser quebrada em partes menores para ser "digerida":

- **Milestones:** S√£o os grandes peda√ßos da pedra (objetivos maiores)
- **Issues:** S√£o os fragmentos que voc√™ consegue consumir (tarefas espec√≠ficas)

As issues no GitHub s√£o usadas para apontar problemas ou tarefas espec√≠ficas dentro do reposit√≥rio.

## Aula 10: Padroniza√ß√£o de C√≥digo

### EditorConfig

O EditorConfig ajuda a manter estilos de codifica√ß√£o consistentes entre diferentes editores e IDEs.

1. Crie o arquivo `.editorconfig` na raiz do projeto com o seguinte conte√∫do:

```
root = true

[*]
indent_style = space
indent_size = 2
```

2. Instale a extens√£o "EditorConfig for VS Code" para que o editor respeite estas configura√ß√µes.

### Prettier

O Prettier √© uma ferramenta que formata automaticamente seu c√≥digo para manter um estilo consistente.

1. Instale o Prettier como depend√™ncia de desenvolvimento:

```bash
npm install prettier -D
```

2. Adicione os scripts de verifica√ß√£o e corre√ß√£o no `package.json`:

```json
"scripts": {
  "dev": "next dev",
  "lint:check": "prettier --check .",
  "lint:fix": "prettier --write ."
}
```

3. Configure o VS Code:
   - Instale a extens√£o do Prettier
   - Abra as configura√ß√µes de Open User Settings (Ctrl + Alt + P)
   - Defina o Prettier como formatador padr√£o nas configura√ß√µes:

     ![Configura√ß√£o do Prettier](./class-images/class-10/prettier.png)

   - Habilite a op√ß√£o "Format On Save":

     ![Format On Save](./class-images/class-10/prettier-1.png)

   - Desabilite o "Auto Save" para ter mais controle sobre quando salvar os arquivos:

     ![Auto Save](./class-images/class-10/prettier-2.png)

OBS: O Preetier √© para salvar as configura√ß√µes depoisd e escrever o c√≥digo, o editorConfig √© durante

## Aula 12: Registro de Dom√≠nio Pr√≥prio

### O que √© um registrador de dom√≠nio?

- Um registrador de dom√≠nio √© respons√°vel por registrar e gerenciar dom√≠nios na internet.
- No Brasil, o principal registrador √© o [registro.br](https://registro.br/).
- Todos os dom√≠nios ficam registrados no "Registry", que no Brasil √© o nic.br.

  ![Registro de dom√≠nio](./class-images/class-12/aula-12-1.png)

### Como configurar o DNS na Vercel

1. Acesse o painel da Vercel e entre na se√ß√£o **Domain**.
2. Clique em **ADD** para adicionar um novo dom√≠nio.

   ![Adicionar dom√≠nio](./class-images/class-12/aula-12-2.png)

3. Escolha o projeto e insira o dom√≠nio desejado.

   ![Escolher projeto e dom√≠nio](./class-images/class-12/aula-12-3.png)

4. Copie os servidores DNS fornecidos pela Vercel.

   ![Copiar DNS da Vercel](./class-images/class-12/aula-12-4.png)

5. Acesse o site [registro.br](https://registro.br/) e cole os DNSs copiados na configura√ß√£o do seu dom√≠nio.
6. Aguarde a atualiza√ß√£o do sistema do registro.br para que o dom√≠nio fique ativo.

   ![Configurar DNS no registro.br](./class-images/class-12/aula-12-5.png)

## Aula 14: PoC e MVP

### O que s√£o PoC e MVP?

- **PoC (Prova de Conceito):** Demonstra a viabilidade t√©cnica de uma ideia ou solu√ß√£o. √â um experimento para validar se algo √© poss√≠vel antes de investir mais tempo e recursos.
- **MVP (Produto M√≠nimo Vi√°vel):** √â a vers√£o mais simples de um produto que j√° entrega valor ao usu√°rio. O objetivo √© lan√ßar rapidamente para obter feedback real e evoluir o produto de forma iterativa.

#### Perguntas para guiar o desenvolvimento

- **Para PoC:**
  - Qual o menor custo que posso ter para mostrar a dire√ß√£o que devo seguir?
  - Qual a prova que confirma (ou n√£o) o conceito que quero validar?

- **Para MVP:**
  - O que √© o m√≠nimo que posso fazer, mas muito bem feito, para j√° resolver o problema do usu√°rio?
  - Qual o menor custo para entregar algo funcional ao usu√°rio?

---

### Milestone 1: Funda√ß√£o

√â interessante come√ßar com uma PoC do front-end, mesmo que simples. O importante √© ter uma base inicial para construir e evoluir o projeto.

### "Overengineering"

Evite complicar demais o projeto desde o in√≠cio. Foque no essencial e v√° adicionando complexidade conforme necess√°rio. O objetivo √© entregar algo funcional rapidamente, sem se perder em detalhes desnecess√°rios.

Fazer o simples bem feito √© mais importante do que fazer algo complexo e cheio de recursos que n√£o s√£o necess√°rios no momento.

## Aula 13: Testes automatizados

O nosso Teste Runner (framework de testes) √© o Jest, instalamos ele como depend√™ncia de desenvolvimento:

```bash
npm install jest -D
```

Agora adicionar os scripts de teste no `package.json`:

```json
"scripts": {
  "test": "jest",
  "test:watch": "jest --watch"
}
```

√â assim que se espera que os testes sejam executados, com "expect" e "toBe" para verificar os resultados.
![alt text](./class-images/class-15/aula-15-1.png)

```javascript
test("soma de dois n√∫meros", () => {
  expect(valorDinamico).toBe("12");
});
```

Aqui nesse exemplo, o "expect" espera um valor din√¢mico, enquanto o "toBe" espera um valor est√°tico. O Jest vai comparar o resultado da soma com o valor esperado.

Pode-se ler assim: Espera-se que algo vindo do sistema (expect, valor din√¢mico) possua o resultado declarado (toBe, hardcoded).

## Aula 16: Testes

### Tipos de Testes

- **Teste Unit√°rio:** Testa uma unidade espec√≠fica do c√≥digo, como uma fun√ß√£o ou m√©todo isolado. N√£o depende de outras partes do sistema ou de infraestrutura externa (ex: banco de dados). S√£o independentes e autossuficientes.
- **Teste de Integra√ß√£o:** Testa a intera√ß√£o entre diferentes partes do sistema, como m√≥dulos ou componentes. Garante que as unidades funcionam bem juntas e podem envolver depend√™ncias externas, como banco de dados ou APIs.
- **Teste E2E (End-to-End):** Testa o sistema como um todo, simulando o comportamento do usu√°rio final e verificando se todas as partes funcionam juntas corretamente.

![Tipos de Testes](/class-images/class-16/imagem-16-1.png)

### Por que precisamos de testes?

Garantir que as "pe√ßas do quebra-cabe√ßa" do software se encaixem √© fundamental. N√£o adianta cada parte funcionar sozinha se, juntas, n√£o entregam o resultado esperado. Mudan√ßas em uma parte do sistema podem causar erros em cadeia. Testes de unidade e integra√ß√£o ajudam a evitar esses problemas ao garantir que altera√ß√µes n√£o quebrem o funcionamento do sistema.

### Diferen√ßa entre tipos de testes

- **Teste de unidade:** C√≥digo que funciona por conta pr√≥pria, sem depend√™ncias externas.
- **Teste de integra√ß√£o:** Foca na integra√ß√£o entre unidades ou camadas da aplica√ß√£o/infrastrutura. Mesmo com 100% de cobertura em testes de unidade, o sistema pode n√£o funcionar se as integra√ß√µes falharem. Exemplo: testar uma chamada HTTP que acessa um banco de dados.
- **Teste E2E:** O mais fiel ao ambiente real, simulando a experi√™ncia do usu√°rio final. Pode envolver deploy em infraestrutura semelhante √† produ√ß√£o.

### Velocidade e custos

Quanto mais abrangente o teste, mais lento ele tende a ser. Testes E2E, por exemplo, podem exigir infraestrutura adicional e simula√ß√£o de navegadores, tornando-os mais demorados. Em projetos grandes, a execu√ß√£o de todos os testes pode impactar o tempo de entrega de corre√ß√µes r√°pidas (hotfixes).

### Modelos de Testes

- **Pir√¢mide de Testes:** Proposta por Mike Cohn (2009), sugere ter mais testes unit√°rios, alguns de integra√ß√£o e poucos E2E.
- **Trof√©u de Testes:** Proposta por Guillermo Rauch (criador do Next.js), valoriza mais os testes de integra√ß√£o.
- **Modelo Favo de Mel do Spotify:** Tamb√©m d√° mais import√¢ncia aos testes de integra√ß√£o.

### Como distinguir testes de unidade e integra√ß√£o

Antigamente, testes de unidade eram feitos por desenvolvedores e testes de integra√ß√£o pelo time de qualidade. Hoje, muitos defendem que o importante √© ter testes r√°pidos e confi√°veis, independentemente da divis√£o cl√°ssica. Se n√£o for poss√≠vel implementar todos os tipos, priorize os testes de integra√ß√£o, pois eles garantem que as partes do sistema funcionam juntas.

> **Dica:** Projetos como Pagar.me e TabNews priorizaram testes de integra√ß√£o para garantir que a API funcionasse corretamente, j√° que o mais importante era a integra√ß√£o das partes.

---

### Encostando a m√£o no Protocolo HTTP

**Endpoint** √© o endere√ßo de uma API. Tudo com o que voc√™ interage provavelmente √© uma interface, que abstrai detalhes de implementa√ß√£o.

Para criar um endpoint no Next.js, crie um arquivo em `pages/api`. Exemplo de rota: `http://localhost:3000/api/status`.

![Exemplo de endpoint](/class-images/class-16/image-16-2.png)

```javascript
function status(request, response) {
  response.status(200).json({ status: "ok" });
}

export default status;
```

**CURL** √© uma ferramenta de linha de comando para fazer requisi√ß√µes HTTP.

```bash
curl -v http://localhost:3000/api/status
```

![Exemplo CURL](/class-images/class-16/image-16-3.png)

Para visualizar detalhes do protocolo HTTP, utilize o par√¢metro `-v`:

```bash
curl -v http://localhost:3000/api/status
```

![Detalhes HTTP](/class-images/class-16/image-16-4.png)

## Aula 17: Qual banco de dados escolher?

Existem tr√™s decis√µes principais na hora de escolher a arquitetura de dados para um projeto:

- SGBD (Sistema de Gerenciamento de Banco de Dados): software que armazena e gerencia os dados. Exemplos: PostgreSQL, MySQL, MongoDB.
- Biblioteca de acesso / ORM: abstra√ß√£o para fazer queries e mapear modelos no c√≥digo. Exemplos: Prisma, Sequelize, TypeORM.
- Migrations: scripts que versionam o esquema do banco (cria√ß√£o/altera√ß√£o de tabelas). Exemplos: Prisma Migrate, TypeORM Migrations.

![Etapas de escolha](/class-images/class-17/image.png)

As escolhas do Filipe para este curso est√£o ilustradas abaixo:
![Escolhas do Filipe](/class-images/class-17/image-1.png)

### Por que o Docker virou padr√£o?

Antes cada desenvolvedor rodava tudo na pr√≥pria m√°quina, o que gerava a famosa frase "na minha m√°quina funciona". M√°quinas virtuais resolveram parte do problema, mas s√£o pesadas.

O Docker trouxe containers leves que compartilham o kernel do sistema operacional, permitindo ambientes isolados, reprodut√≠veis e mais r√°pidos. Isso facilita desenvolver, testar e distribuir imagens (ex.: enviar para o Docker Hub).

![Docker](/class-images/class-17/image-2.png)

### Subir um banco de dados local (exemplo: PostgreSQL)

Crie um arquivo de composi√ß√£o na raiz do projeto (ex.: docker-compose.yml) e adicione um servi√ßo de banco:

```yaml
# docker-compose.yml
version: "3.9"

services:
  database:
    image: postgres:17.6-alpine3.21
    environment:
      POSTGRES_PASSWORD: local_password
    ports:
      - "5432:5432"
```

Suba o container em segundo plano:

```bash
docker compose up -d
```

### Conectando ao PostgreSQL local

Instale o cliente psql (Ubuntu/Debian):

```bash
sudo apt update
sudo apt install -y postgresql-client
```

Conecte-se ao banco:

```bash
psql --host=localhost --port=5432 --username=postgres --dbname=postgres
# ser√° solicitada a senha definida em POSTGRES_PASSWORD (ex: local_password)
```

Para sair do psql, digite:

```bash
\q
```

Se o arquivo docker-compose.yml estiver em outro diret√≥rio, use:

```bash
docker compose -f caminho/para/docker-compose.yml up -d
```

## Aula 18: Criar m√≥dulo "database.js"

No terminal usamos o psql para conectar ao PostgreSQL manualmente. No c√≥digo, usamos o pacote "pg" para conectar ao banco a partir da aplica√ß√£o.
![alt text](/class-images/class-18/image.png)

Instala√ß√£o do pacote "pg":

```bash
npm install pg@8.11.3
```

Ent√£o dentro do diret√≥rio infra, foi criado o modulo database.js, que √© respons√°vel por de baixo dos panos, abrir conex√£o
com o banco de dados, executar uma query e fechar a conex√£o., sem que seja preciso fazer isso em cada arquivo, somente importando ele

```javascript
import { Client } from "pg";

async function query(queryObject) {
  const client = new Client({
    host: "localhost",
    port: 5432,
    user: "postgres",
    database: "postgres",
    password: "local_password",
  });

  await client.connect();
  const result = await client.query(queryObject);
  await client.end();

  return result;
}

export default { query };
```

Ent√£o importamos esse modulo database para dentro do nosso endpoint /api/v1/status, e fazemos uma query de teste, que √© o SELECT 1 + 1 AS sum.

```javascript
import database from "../../../../infra/database.js";

async function status(request, response) {
  const result = await database.query("SELECT 1 + 1 AS sum;");
  console.log(result);
  response.status(200).json({ status: "ok" });
}

export default status;
```

### A import√¢ncia das Vari√°veis de Ambiente

Podemos definir um servi√ßo em tr√™s Camadas:

- Interface
- Aplica√ß√£o
- Persist√™ncia

Enquanto a camada de Interface se preocupa com oferecer o melhor layout e experi√™ncia para o usu√°rio, a camada de Aplica√ß√£o se preocupa com a l√≥gica de neg√≥cio e regras do sistema. J√° a camada de Persist√™ncia √© respons√°vel por armazenar os dados de forma segura e eficiente.

A l√≥gica para um servi√ßo ser Stateless (sem estado) √© que ele n√£o deve depender de informa√ß√µes armazenadas localmente, como em mem√≥ria ou arquivos. Isso permite que o servi√ßo seja escal√°vel e resiliente, j√° que qualquer inst√¢ncia do servi√ßo pode atender a qualquer requisi√ß√£o sem depender de dados espec√≠ficos.
![alt text](/class-images/class-18/image-1.png)

### Vari√°veis de Ambiente no C√≥digo

Criei o arquivo `.env` na raiz do projeto com as seguintes vari√°veis:

```
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_USER=postgres
POSTGRES_DB=postgres
POSTGRES_PASSWORD=local_password
```

E alterei no database.js para pegar essas vari√°veis de ambiente:

```javascript
const client = new Client({
  host: process.env.POSTGRES_HOST,
  port: process.env.POSTGRES_PORT,
  user: process.env.POSTGRES_USER,
  database: process.env.POSTGRES_DB,
  password: process.env.POSTGRES_PASSWORD,
});
```

### Vari√°veis de Ambiente no Docker Compose

Foi alterado o docker-compose.yml para pegar as vari√°veis de ambiente do arquivo .env
foi alterado o environment para env_file

```yaml
version: "3.9"
services:
  database:
    image: postgres:17.6-alpine3.21
    env_file:
      - ../.env
    ports:
      - "5432:5432"
```

### Foi certo fazer o commit do .env?

Segundo a documenta√ß√£o do NextJS sim, .env deveria ser commitado por conter as vari√°veis de ambiente, por√©m como pode haver
dados sens√≠veis, o ideal √© ter um .env.example que n√£o contenha dados sens√≠veis, e sim apenas o nome das vari√°veis, para que
quem for clonar o projeto, saiba quais vari√°veis de ambiente precisa criar.

Por√©m nesse exemplo utilizamos o .env.development, que √© espec√≠fico para o ambiente de desenvolvimento, e n√£o cont√©m dados sens√≠veis.

```bash
mv .env .env.development
```

E no composer.yaml alterei para pegar o .env.development

```yaml
# Qualquer servi√ßo que voc√™ deseja executar deve ser definido aqui.
services:
  database:
    image: "postgres:17.6-alpine3.21"
    env_file:
      - ../.env.development
    ports:
      - "5432:5432"
```

### Caminho Absoluto

Para que o NextJs reconhe√ßa o caminho absoluto, foi criado o arquivo jsconfig.json na raiz do projeto com o seguinte conte√∫do:

```json
{
  "compilerOptions": {
    "baseUrl": "."
  }
}
```

Esse "." √© para referenciar que o caminho absoluto √© a raiz do projeto.

Com isso, podemos importar o database.js de forma absoluta, sem precisar usar o caminho relativo com muitos "../"

```javascript
import database from "infra/database.js";
```

### Configurar scripts dos servi√ßos

Primeiro criamos scripts para subir, parar e derrubar o container do docker, fizemos isso dedntro do package.json

```json
{
  "scripts": {
    "services:up": "docker compose -f infra/compose.yaml up -d",
    "services:stop": "docker compose -f infra/compose.yaml stop",
    "services:down": "docker compose -f infra/compose.yaml down"
  }
}
```

Tamb√©m podemos combinar um comando ap√≥s o outro, como por exemplo subir o conatiner e j√° rodar o service com o nosso comando
npm run dev:

```json
{
  "scripts": {
    "dev": "npm run services:up && next dev"
  }
}
```

## Aula 19:

### Endpoint "/status": ISO 8601 + Fuso + MVC + lowerCamelCase

O padr√£o ISO 8601 √© uma norma internacional que define a representa√ß√£o de datas e horas. Ele √© amplamente utilizado em APIs para garantir que as informa√ß√µes de data e hora sejam transmitidas de forma consistente e sem ambiguidade.

Um exemplo de data no formato ISO 8601 √©: `2023-03-15T13:45:30Z`, que representa 15 de mar√ßo de 2023, √†s 13:45:30 UTC.

Al√©m disso, ao trabalhar com fusos hor√°rios, √© importante considerar a diferen√ßa entre UTC e o hor√°rio local. O padr√£o ISO 8601 permite a inclus√£o de informa√ß√µes de fuso hor√°rio, como `2023-03-15T13:45:30-03:00`, que indica que a hora est√° no fuso hor√°rio de Bras√≠lia (UTC-3).

Controller pede pro model alguma informa√ß√£o ou regra de neg√≥cio

Depois que a Model faz o que tem que ser feito ele retorna essa informa√ß√£o para o Controller.

Ent√£o o Controller manda essa informa√ß√£o para a View, que se responsabiliza em devolver isso para o consumidor final no formato correto.

Para fazer a data atual ser retornada no formato ISO 8601, podemos utilizar o m√©todo `toISOString()` do objeto `Date` em JavaScript. Esse m√©todo retorna uma string no formato ISO 8601, que √© o formato desejado para a nossa API.

```javascript
const updatedAt = new Date().toISOString();
```

OBS: a resposta (View) deve sempre ser feita em `snack case`

```javascript
async function status(request, response) {
  const updatedAt = new Date().toISOString();
  response.status(200).json({
    status: "ok",
    updated_at: updatedAt,
  });
}

export default status;
```

## Aula 20

### Database "Version" (+ Red, Green e Refactor do TDD)

RED √© o estagio do TDD onde os testes falham, pois a funcionalidade ainda n√£o foi implementada.

GREEN √© o est√°gio onde os testes passam, ou seja, a funcionalidade foi implementada corretamente.

REFACTORY √© o est√°gio de quando os testes j√° passaram, ent√£o podemos refatorar o c√≥digo deixando ele mais sem√¢ntico.

Para vermos a vers√£o que esta no Postgres podemos usar a query SHOW, que nos "mostra alguns detalhes da nossa aplica√ß√£o.

```javascript
async function status(request, response) {
  const updatedAt = new Date().toISOString();
  const databaseVersion = await database
    .query("SHOW server_version;")
    .then((result) => result.rows[0].server_version);

  response.status(200).json({
    updated_at: updatedAt,
    dependences: {
      database: {
        version: databaseVersion,
      },
    },
  });
}
```

Foi preciso fazer o then(), pois o retorno do dabase.query √© um array da propriedade row.

```text
Result {
  command: 'SHOW',
  rowCount: null,
  oid: null,
  rows: [ { server_version: '17.6' } ],
  fields: [
    Field {
      name: 'server_version',
      tableID: 0,
      columnID: 0,
      dataTypeID: 25,
      dataTypeSize: -1,
      dataTypeModifier: -1,
      format: 'text'
    }
  ],
  _parsers: [ [Function: noParse] ],
  _types: TypeOverrides {
    _types: {
      getTypeParser: [Function: getTypeParser],
      setTypeParser: [Function: setTypeParser],
      arrayParser: [Object],
      builtins: [Object]
    },
    text: {},
    binary: {}
  },
  RowCtor: null,
  rowAsArray: false,
  _prebuiltEmptyResultObject: { server_version: null }
}
```

### Database "Max Connections"

Podemos pegar a quantidade m√°xima de conex√µes que o banco de dados suporta, com a query SHOW max_connections;

```javascript
async function status(request, response) {
  const updatedAt = new Date().toISOString();
  const databaseVersion = await database
    .query("SHOW server_version;")
    .then((result) => result.rows[0].server_version);

  const maxConnections = await database
    .query("SHOW max_connections;")
    .then((result) => result.rows[0].max_connections);

  response.status(200).json({
    updated_at: updatedAt,
    dependences: {
      database: {
        version: databaseVersion,
        max_connections: parseInt(maxConnections),
      },
    },
  });
}

export default status;
```

E fazemos em seguida o teste de integra√ß√£o para esse endpoint /api/v1/status

```javascript
test("Get to /api/v1/status should return 200", async () => {
  const response = await fetch("http://localhost:3000/api/v1/status");
  expect(response.status).toBe(200);

  const responseBody = await response.json();
  expect(responseBody.updated_at).toBeDefined();

  const parsedUpdatedAt = new Date(responseBody.updated_at).toISOString();
  expect(responseBody.updated_at).toBe(parsedUpdatedAt);

  expect(responseBody.dependences.database.version).toEqual("17.6");
  expect(responseBody.dependences.database.max_connections).toEqual(100);
});
```

### Database "Opened Connections"

Criamos a query para pegar a quantidade de conex√µes abertas no banco de dados, com a query SELECT \* from pg_stat_activity WHERE datname = 'local_db';

```javascript
const databaseOpenedConnectionsResult = await database.query(
  "SELECT count(*)::int from pg_stat_activity WHERE datname = 'local_db';",
);
```

### SQL Injection e Queries Parametrizadas

Primeiro come√ßamos invadindo nosso pr√≥prio banco parametrizando nossa query:

```javascript
const databaseName = request.query.databaseName;
const databaseOpenedConnectionsResult = await database.query(
  `SELECT count(*)::int from pg_stat_activity WHERE datname = '${databaseName}';`,
);
```

Ent√£o, nos testes de integra√ß√£o, criamos um teste que simula um ataque de SQL Injection:

```javascript
test.only("Teste SQL Injection", async () => {
  await fetch(
    "http://localhost:3000/api/v1/status?databaseName='; SELECT pg_sleep(4); --",
  );
});
```

Dessa forma o nosso banco de dados fica vulner√°vel a ataques de SQL Injection, onde um atacante pode manipular a query para executar comandos maliciosos.

Para evitar isso, devemos utilizar queries parametrizadas, onde os valores s√£o passados separadamente da query, evitando que o atacante consiga manipular a query.

```javascript
const databaseName = process.env.POSTGRES_DB;
const databaseOpenedConnectionsResult = await database.query({
  text: "SELECT count(*)::int from pg_stat_activity WHERE datname = $1;",
  values: [databaseName],
});
```

Um outro ponto muito importante √© a quest√£o do fechamento da connex√£o com o banco ded dados, sempre que ocorre algum erro fica uma conex√£o aberta, e isso pode levar o banco a ficar sem conex√µes dispon√≠veis.

Para sempre evitar isso e garantir que haver√° o fechamento da conex√£o, independente se ocorrer um erro ou n√£o, podemos utilizar o try...catch...finally

```javascript
import { Client } from "pg";

async function query(queryObject) {
  const client = new Client({
    host: process.env.POSTGRES_HOST,
    port: process.env.POSTGRES_PORT,
    user: process.env.POSTGRES_USER,
    database: process.env.POSTGRES_DB,
    password: process.env.POSTGRES_PASSWORD,
  });

  try {
    await client.connect();
    const result = await client.query(queryObject);

    return result;
  } catch (error) {
    console.error("Database query error:", error);
  } finally {
    await client.end();
  }
}

export default { query };
```

## Aula 21

### Investigando logs da Vercel em Produ√ß√£o

Para investigar melhor o que de fato esta acontecendo em produ√ß√£o, podemos adicionar mais logs no nosso c√≥digo, para termos mais informa√ß√µes do que esta acontecendo.

No arquivo infra/database.js, adicionei um console.log para imprimir as credenciais do banco de dados que est√£o sendo usadas na conex√£o.

```javascript
import { Client } from "pg";

async function query(queryObject) {
  const client = new Client({
    host: process.env.POSTGRES_HOST,
    port: process.env.POSTGRES_PORT,
    user: process.env.POSTGRES_USER,
    database: process.env.POSTGRES_DB,
    password: process.env.POSTGRES_PASSWORD,
  });

  console.log("Credenciais do Postgres: ", {
    host: process.env.POSTGRES_HOST,
    port: process.env.POSTGRES_PORT,
    user: process.env.POSTGRES_USER,
    database: process.env.POSTGRES_DB,
    password: process.env.POSTGRES_PASSWORD,
  });

  try {
    await client.connect();
    const result = await client.query(queryObject);

    return result;
  } catch (error) {
    console.error("Database query error:", error);
    throw error;
  } finally {
    await client.end();
  }
}

export default { query };
```

Com isso ap√≥s acessar a rota `/api/v1/status` em produ√ß√£o, podemos ver nos logs da Vercel as credenciais que est√£o sendo usadas para conectar no banco de dados.
![alt text](/class-images/class-21/image.png)

### Banco de Produ√ß√£o

Criamos uma conta na NeonDB, que √© um servi√ßo de banco de dados PostgreSQL na nuvem, e criamos um banco de dados chamado `tabnews_clone`.

Dentro dela criamos uma inst√¢ncia do banco PostgreSQL, e pegamos as credenciais para conectar no banco.

Ent√£o entramos no .env do projeto e adicionamos as credenciais do banco de produ√ß√£o.

```
POSTGRES_HOST=ep-lingering-snow-779165.us-east-2.aws.neon.tech
POSTGRES_PORT=5432
POSTGRES_USER=your_username
POSTGRES_DB=tabnews_clone
POSTGRES_PASSWORD=your_password
```

Com isso conseguimos acessar a rota `/api/v1/status` em localmente, e ver que agora estamos conectando no banco de produ√ß√£o.

Depois entramos na vercel e colocamos as mesmas vari√°veis de ambiente do .env, para que em produ√ß√£o o projeto consiga conectar no banco de produ√ß√£o.

## Aula 22

Iremos utilizar o node-pg-migration que √© uma ferramenta para controle de migra√ß√£o de banco de dados para PostgreSQL.

### Instala√ß√£o do node-pg-migration

```bash
npm install node-pg-migrate@6.2.2
```

Adicionamos o script no package.json para criar uma nova migration:

```json
"scripts": {
    "migrate:create": "node-pg-migrate --migrations-dir infra/migrations create"
  }
```

Para testes foi rodado uma migration teste:

```bash
npm run migration:create first migrate teste
```

Vamos adicionar o modulo "dotenv" para carregar as vari√°veis de ambiente do .env

```bash
npm install dotenv@16.4.4
```

E alteramos o script, informando qual o arquivo do .env.development

```json
"scripts": {
    "migrate:up": "node-pg-migrate --migrations-dir infra/migrations --envPath .env.development up"
}
```

Adicionamos a nova vari√°vel de ambiente DATABASE_URL no .env.development

```bash
DATABASE_URL=postgres://local_user:local_password@localhost:5432/local_db
```

## Aula 23

### Migrations pelo endpoint ‚Äú/migrations‚Äù (Dry Run)

Documenta√ß√£o que iremos utilizar da parte program√°tica do node-pg-migrate, que permite fazer a mesma coisa que o CLI, mas de forma program√°tica (c√≥digo).
https://salsita.github.io/node-pg-migrate/api

Modo Dry Run √© uma funcionalidade que permite simular a execu√ß√£o de uma opera√ß√£o sem realmente aplic√°-la. No contexto de migra√ß√µes de banco de dados, o Dry Run permite verificar quais mudan√ßas seriam feitas no banco sem realmente execut√°-las. Isso √© √∫til para revisar as altera√ß√µes antes de aplic√°-las, garantindo que tudo esteja correto e evitando poss√≠veis erros.

Modo Live Run √© o modo normal de execu√ß√£o, onde as mudan√ßas s√£o realmente aplicadas ao banco de dados. Nesse modo, as migra√ß√µes s√£o executadas e as altera√ß√µes s√£o feitas no banco conforme definido nos arquivos de migra√ß√£o.

Ent√£o criamos o endpoint /api/v1/migrations, que ao ser acessado, executa as migra√ß√µes em modo Dry Run, ou seja, simula a execu√ß√£o das migra√ß√µes sem realmente aplic√°-las ao banco de dados.

```bash
tests/integration/api/v1/migrations/get.test.js
```

```javascript
test("Get to /api/v1/migrations should return 200", async () => {
  const response = await fetch("http://localhost:3000/api/v1/migrations");
  const responseBody = await response.json();

  expect(response.status).toBe(200);
  expect(Array.isArray(responseBody)).toBe(true);
  expect(responseBody.length).toBeGreaterThanOrEqual(0);
});
```

E utilizamos o migrationrunner do node-pg-migrate para executar as migra√ß√µes em modo Dry Run:

```javascript
export default async function migrations(request, response) {
  const migrations = await migrateRunner({
    databaseUrl: process.env.DATABASE_URL,
    dryRun: true,
    dir: join("infra", "migrations"),
    direction: "up",
    verbose: true,
    migrationsTable: "pgmigrations",
  });

  response.status(200).json(migrations);
}
```

### Migrations pelo endpoint ‚Äú/migrations‚Äù (Live Run)

Para executar as migra√ß√µes em modo Live Run, ou seja, aplicando as mudan√ßas ao banco de dados, criamos um teste para rodar com o metodo POST:

```javascript
test("Post to /api/v1/migrations should return 200", async () => {
  const response = await fetch("http://localhost:3000/api/v1/migrations", {
    method: "POST",
  });

  const responseBody = await response.json();
  expect(Array.isArray(responseBody)).toBe(true);
});
```

e alteramos a controller para se receber um GET, rodar em modo Dry Run, e se receber um POST, rodar em modo Live Run:

```javascript
import migrateRunner from "node-pg-migrate";
import { join } from "node:path";

export default async function migrations(request, response) {
  if (request.method === "GET") {
    const migrations = await migrateRunner({
      databaseUrl: process.env.DATABASE_URL,
      dryRun: true,
      dir: join("infra", "migrations"),
      direction: "up",
      verbose: true,
      migrationsTable: "pgmigrations",
    });

    return response.status(200).json(migrations);
  }

  if (request.method === "POST") {
    const migrations = await migrateRunner({
      databaseUrl: process.env.DATABASE_URL,
      dryRun: false,
      dir: join("infra", "migrations"),
      direction: "up",
      verbose: true,
      migrationsTable: "pgmigrations",
    });

    return response.status(200).json(migrations);
  }

  return response.status(405).json({ message: "Method not allowed" });
}
```

## Aula 24

### Fazendo o Jest "transpilar" arquivos em ESM

#### Problema: Testes rodando em paralelo

O primeiro objetivo foi fazer o Jest parar de rodar de forma paralela e passar a rodar de forma linear (sequencial). Isso √© importante para testes de integra√ß√£o que compartilham o mesmo banco de dados, pois testes paralelos podem causar condi√ß√µes de corrida (race conditions) e resultados inconsistentes.

Para resolver isso, adicionamos a flag `--runInBand` no script de teste do `package.json`:

```json
"test": "jest --runInBand",
"test:watch": "jest --watchAll --runInBand",
```

A flag `--runInBand` for√ßa o Jest a executar todos os testes em s√©rie, um ap√≥s o outro, no mesmo processo.

#### Problema: Jest n√£o suporta ESM nativamente

Encontramos um novo problema: por padr√£o, o Jest n√£o possui as configura√ß√µes necess√°rias para trabalhar com ECMAScript Modules (ESM), que √© o padr√£o moderno do JavaScript utilizado no projeto com `import/export`.

#### Solu√ß√£o: Integrar Jest com Next.js

Precisamos fazer com que o Jest possua os mesmos "poderes" do Next.js para transpilar arquivos ESM. Para isso, criamos o arquivo `jest.config.js` na raiz do projeto:

```javascript
const dotenv = require("dotenv");
dotenv.config({
  path: ".env.development",
}); // Carrega as vari√°veis de ambiente do .env para o process.env

const nextJest = require("next/jest"); // D√° para o Jest os "poderes" do Next.js

const createJestConfig = nextJest();
const jestConfig = createJestConfig({
  moduleDirectories: ["node_modules", "<rootDir>"],
  testEnvironment: "node",
});

module.exports = jestConfig;
```

**O que cada parte faz:**

1. **`dotenv.config()`**: Carrega as vari√°veis de ambiente do arquivo `.env.development` para o `process.env`, garantindo que os testes tenham acesso √†s mesmas configura√ß√µes do ambiente de desenvolvimento.

2. **`require("next/jest")`**: Importa a fun√ß√£o de configura√ß√£o do Jest fornecida pelo Next.js, que j√° vem configurada para trabalhar com ESM, TypeScript e outras features modernas.

3. **`moduleDirectories`**: Define onde o Jest deve procurar por m√≥dulos. O `<rootDir>` permite usar imports absolutos (como `import database from "infra/database.js"`) em vez de relativos (como `import database from "../../../../infra/database.js"`).

4. **`testEnvironment: "node"`**: Define que os testes ser√£o executados em ambiente Node.js (n√£o em ambiente de navegador/DOM), que √© apropriado para testes de API e integra√ß√£o com banco de dados.

#### Problema: Fetch n√£o dispon√≠vel no Node.js

Como o `fetch` n√£o √© nativo em vers√µes antigas do Node.js, foi necess√°rio adicionar o polyfill `node-fetch` nos arquivos de teste:

```javascript
import fetch from "node-fetch";
globalThis.fetch = fetch;
```

Isso garante que o `fetch` esteja dispon√≠vel globalmente em todos os testes, simulando o comportamento do navegador.

#### Isolamento de testes com cleanDatabase

Para garantir que cada teste comece com um banco de dados limpo (evitando interfer√™ncia entre testes), criamos a fun√ß√£o `cleanDatabase` que √© executada antes de todos os testes:

```javascript
beforeAll(cleanDatabase);

async function cleanDatabase() {
  // Derrubar todas as tabelas do banco de dados
  // E depois recriar o schema public
  await database.query("drop schema public cascade; create schema public;");
}
```

**Como funciona:**

- `DROP SCHEMA public CASCADE`: Remove o schema p√∫blico e todas as suas depend√™ncias (tabelas, √≠ndices, etc.)
- `CREATE SCHEMA public`: Recria o schema p√∫blico vazio
- `beforeAll()`: Hook do Jest que executa a fun√ß√£o antes de todos os testes do arquivo

Isso garante um ambiente limpo e previs√≠vel para cada execu√ß√£o de testes.

#### Estrutura final dos testes

Com todas essas configura√ß√µes, os testes de integra√ß√£o ficaram organizados da seguinte forma:

**GET /api/v1/migrations** (`tests/integration/api/v1/migrations/get.test.js`):

```javascript
import database from "infra/database.js";
import fetch from "node-fetch";

globalThis.fetch = fetch;

beforeAll(cleanDatabase);

async function cleanDatabase() {
  await database.query("drop schema public cascade; create schema public;");
}

test("Get to /api/v1/migrations should return 200", async () => {
  const response = await fetch("http://localhost:3000/api/v1/migrations");
  const responseBody = await response.json();

  expect(response.status).toBe(200);
  expect(Array.isArray(responseBody)).toBe(true);
  expect(responseBody.length).toBeGreaterThanOrEqual(0);
});
```

**POST /api/v1/migrations** (`tests/integration/api/v1/migrations/post.test.js`):

```javascript
import database from "infra/database.js";
import fetch from "node-fetch";

globalThis.fetch = fetch;

beforeAll(cleanDatabase);

async function cleanDatabase() {
  await database.query("drop schema public cascade; create schema public;");
}

test("POST to /api/v1/migrations should return 200", async () => {
  const response = await fetch("http://localhost:3000/api/v1/migrations", {
    method: "POST",
  });

  const responseBody = await response.json();
  expect(response.status).toBe(200);
  expect(Array.isArray(responseBody)).toBe(true);
});
```

#### Resumo das altera√ß√µes

1. ‚úÖ Testes agora rodam de forma sequencial (`--runInBand`)
2. ‚úÖ Jest configurado para trabalhar com ESM atrav√©s do Next.js
3. ‚úÖ Vari√°veis de ambiente carregadas automaticamente nos testes
4. ‚úÖ Fetch dispon√≠vel globalmente via `node-fetch`
5. ‚úÖ Banco de dados limpo antes de cada arquivo de teste
6. ‚úÖ Imports absolutos funcionando nos testes

Com essa estrutura, os testes de integra√ß√£o s√£o confi√°veis, isolados e podem ser executados de forma consistente em qualquer ambiente.

## Aula 25: Deploys e Migra√ß√£o em Produ√ß√£o

### Instalando o dotenv-expand

O pacote `dotenv-expand` √© uma extens√£o do `dotenv` que permite expandir vari√°veis de ambiente que referenciam outras vari√°veis. Isso √© √∫til quando voc√™ deseja criar vari√°veis compostas ou reutilizar valores j√° definidos.

no termianal, instalei o pacote:

```bash
npm install dotenv-expand@11.0.6
```

ai meu .env.development ficou assim:

```
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_USER=local_user
POSTGRES_PASSWORD=local_password
POSTGRES_DB=local_db
DATABASE_URL=postgres://$POSTGRES_USER:$POSTGRES_PASSWORD@$POSTGRES_HOST:$POSTGRES_PORT/$POSTGRES_DB
NODE_ENV=development
```

### Criando uma conex√£o com o banco

No arquivo infra/database.js, criei o m√©todo assincrono getNewClient. Ele retorna uma inst√¢ncia conectada do banco de dados PostgreSQL usando as vari√°veis de ambiente para configura√ß√£o.

```javascript
import { Client } from "pg";

async function query(queryObject) {
  let client;
  try {
    client = await getNewClient();
    const result = await client.query(queryObject);

    return result;
  } catch (error) {
    console.error("Database query error:", error);
    throw error;
  } finally {
    await client.end();
  }
}

async function getNewClient() {
  const client = new Client({
    host: process.env.POSTGRES_HOST,
    port: process.env.POSTGRES_PORT,
    user: process.env.POSTGRES_USER,
    database: process.env.POSTGRES_DB,
    password: process.env.POSTGRES_PASSWORD,
    ssl: process.env.NODE_ENV === "production" ? true : false,
  });

  await client.connect();
  return client;
}

export default { query, getNewClient };
```

Agora chamamos ela no @pages/api/v1/migrations/index.js

```javascript
import migrateRunner from "node-pg-migrate";
import { join } from "node:path";
import database from "infra/database.js";

export default async function migrations(request, response) {
  const dbClient = await database.getNewClient();
  const defaulMigrationsOptions = {
    dbClient,
    dryRun: true,
    dir: join("infra", "migrations"),
    direction: "up",
    verbose: true,
    migrationsTable: "pgmigrations",
  };

  if (request.method === "GET") {
    const pendingMigrations = await migrateRunner(defaulMigrationsOptions);

    await dbClient.end();
    return response.status(200).json(pendingMigrations);
  }

  if (request.method === "POST") {
    const migratedMigrations = await migrateRunner({
      ...defaulMigrationsOptions,
      dryRun: false,
    });

    await dbClient.end();

    if (migratedMigrations.length > 0) {
      return response.status(201).json(migratedMigrations);
    }

    return response.status(200).json(migratedMigrations);
  }

  return response.status(405).json({ message: "Method not allowed" });
}
```

## Aula 26: Cria√ß√£o de ambiente homologa√ß√£o

### Fazendo deploy em Homologa√ß√£o (Staging)

Primeiro passo foi criar um novo database dentro do Projeto Neon, chamamos ele de `staging`
![alt text](/class-images/class-26/image.png)

Depois, va Vercel, configuramos essas vari√°veis de ambiente, por√©m somente para o Preview (esse √© o nome que a Vercel chama o ambiente de homologa√ß√£o).
![alt text](/class-images/class-26/image-1.png)

Para finalizar, criamos um arquivo chamado `cabelo.tx`e adicionamos ao staged (fizemos commit), depois deletamos esse arquivo e fizmos um novo commit
![alt text](/class-images/class-26/image-2.png)
OBS: tivemos que fazer isso, para poder gerar um novo deploy para o ambiente de homologa√ß√£o (Preview) da Vercel.

Ent√£o por √∫ltimo criamos uma nova branch e subimos ela (git push), com isso na Vercel foi gerado um novo deploy para o ambiente de homologa√ß√£o (Preview).
![alt text](/class-images/class-26/image-3.png)

## Melhorando visibilidade dos logs em Produ√ß√£o via curl

Utilizamos a lib `json.tool` do python3 para visualizar melhor os logs do cli

```bash
curl -s https://tabnews-clone-filipe.vercel.app/api/v1/status | python3 -m json.tool
```

# Aula 27

## Git Reflog

O comando `git reflog` √© uma ferramenta poderosa que permite visualizar o hist√≥rico de refer√™ncias do Git, incluindo commits, branches e outras opera√ß√µes. Ele registra todas as mudan√ßas feitas no reposit√≥rio, mesmo aquelas que n√£o s√£o vis√≠veis no hist√≥rico padr√£o do Git.

# Aula 29

## Estabilizar "npm run dev"

Estabilizar Ambientes Locais

- Altera√ß√µes no script "dev"

Vamos resolver isso, como usamos um banco ded dados relacional, a migration precisa ser feita no comando "npm run dev" para que o banco de dados esteja com o schema atualizado.

Alteramos o package.json

```json
"scripts": {
    "dev": "npm run services:up && npm run migration:up && next dev"
  }
```

Por√©m se rodar o comando "npm run dev" com o container desabilitado aconteceu um erro, pois o docker esta funcionando em modo detach, ou seja, j√° vai direto para o background e os demais comandos j√° s√£o executados, por√©m at√© o momento ele ainda n√£o "rodou completamente" o que n√£o permite que seja feita a migration

Para resolver o problema foi criado um script para verificar se j√° esta tudo correto para subir as migrations (wait-for-postgres)

Ent√£o foi criado esse arquivo em infra/scripts/wait-for-postgres.js

E colocamos a chamada desse script no package.json

```json
"scripts": {
    "wait-for-postgres": "node infra/scripts/wait-for-postgres.js"
  }
```

Vamos dar um nome para um container, para poder rodar um comando que verifica a conex√£o do banco de dados

- altera√ß√£o √© feita no compose.yaml

```yaml
services:
  database:
    container_name: "postgres-dev"
```

Para conseguir processar comandos dentro de um script utilizamos o child_process, que permite executar comandos do sistema operacional a partir do Node.js.
Vamos utilizar o m√©todo exec dele para executar o comando psql que verifica a conex√£o com o banco de dados.

```javascript
const { exec } = require("node:child_process");

function checkPostgres() {
  exec("docker exec postgres-dev pg_isready", handleReturn);

  function handleReturn(error, stdout) {
    if (stdout.search("accepting connections") === -1) {
      console.log("N√£o esta aceitando conex√µes ainda.");
      return;
    }

    console.log("‚úÖ Postgres est√° aceitando conex√µes!");
  }
}

console.log("üî¥ Aguardando Postgres aceitar conex√µes");
checkPostgres();
```

Resultado final do arquivo

```javascript
const { exec } = require("node:child_process");

function checkPostgres() {
  exec("docker exec postgres-dev pg_isready --host localhost", handleReturn);

  function handleReturn(error, stdout) {
    if (stdout.search("accepting connections") === -1) {
      process.stdout.write(".");
      checkPostgres();
      return;
    }

    process.stdout.write("\n‚úÖ Postgres est√° aceitando conex√µes!\n");
  }
}

process.stdout.write("\n\nüî¥ Aguardando Postgres aceitar conex√µes\n");
checkPostgres();
```

## Estabilizar "npm test" (Paralelismo)

A ideia √© quando rodar o comando "npm test" ele j√° suba o container do banco de dados, aguarde ele estar pronto para aceitar conex√µes, rode as migrations e s√≥ depois rode os testes.

Se somente faezr isso:

```json
  "test": "npm run services:up && npm run wait-for-postgres && jest --runInBand",
```

N√£o vai dar certo porque o comando "npm run services:up" roda em modo detach, ou seja, ele j√° vai direto para o background e os demais comandos j√° s√£o executados, por√©m at√© o momento ele ainda n√£o "rodou completamente" o que n√£o permite que seja feita a migration e os testes.

Esse erro tamb√©m ocorre porque o nosso servidor "next dev" ainda n√£o esta de p√©. Mas diferente do container, o servidor n√£o possui um modo detach, que roda enquanto o pr√≥ximo comando √© executado.

Vamos resolver esse problema em duas etapas: Primeiro fazer eles rodarem de forma concorrente e depois fazer um orquestrador

Para fazer rodar de forma concorrente, vamos utilizar o pacote `concurrently`, que permite executar m√∫ltiplos comandos npm em paralelo.
https://www.npmjs.com/package/concurrently

```bash
npm install --save-dev concurrently@8.2.2
```

Com esse pacote instalado j√° posso usar os comando em modo concorrente:

```json
    "test": "npm run services:up && npm run wait-for-postgres && concurrently 'next dev' 'jest --runInBand'",
```

Como podemos ver esse vem com um colchete informando qual o comando que esta sendo executado, neste exemplo, o [0] √© o next dev e o [1] √© o jest.
![alt text](class-images/class-29/image.png)

Para melhorar a visualiza√ß√£o, vamos utilizar o par√¢metro `--names` para definir nomes personalizados para cada comando, vamos usar a maneira abreviada que √© "-n".

```json
    "test": "npm run services:up && npm run wait-for-postgres && concurrently --n next,jest 'next dev' 'jest --runInBand'",
```

![alt text](class-images/class-29/image-1.png)

Agora que temos eles nomeados podemos esconder o que n√£o nos interessa, como estamos trabalhando com testes, o que nos interessa √© o jest, ent√£o podemos esconder o next dev., para isso usamos o par√¢metro "--hide"

```json
    "test": "npm run services:up && npm run wait-for-postgres && concurrently --n next,jest --hide next 'next dev' 'jest --runInBand'",
```

![alt text](class-images/class-29/image-2.png)

Um outro ponto que esta incomodando √© fato de sempre precisar pressionar o CRTL+C para finalizar o comando, para resolver isso usamos outro parametro que √© o "--kill-others", que finaliza todos os comandos quando um deles finalizar. A vers√£o mais curta dele √© "-k"

```json
    "test": "npm run services:up && npm run wait-for-postgres && concurrently --n next,jest --hide next --kill-others 'next dev' 'jest --runInBand'",
```

![alt text](class-images/class-29/image-3.png)

Um ultimo ponto √© que mesmo quando o comando de sa√≠da do jest √© success (0), o concurrently retorna um comando de falha (1), precisamos definir qual o comando o concurrently deve considerar como sucesso, para isso usamos o par√¢metro "--success", que tem a vers√£o curta "-s". Nesse caso queremos que o concurrently considere como sucesso quando o jest finalizar com sucesso, ou seja, com o c√≥digo 0.

```json
    "test": "npm run services:up && npm run wait-for-postgres && concurrently --n next,jest  --hide next --k --success command-jest 'next dev' 'jest --runInBand'",
```

![alt text](class-images/class-29/image-4.png)

OBS: O comando "echo $?" no terminal retorna o c√≥digo de sa√≠da do √∫ltimo comando executado. Um c√≥digo de sa√≠da 0 geralmente indica sucesso, enquanto qualquer outro valor indica algum tipo de erro ou falha.

## Estabilizar "npm test" (Orquestrador)

Vamos verificar nosso /status, confirmando que el√ße esta de p√© e retornando um json v√°lido, dessa forma confirmamos que o servidor esta funcionando corretamente.

Vamos utilizar um m√≥dulo chamado "async-retrail", que recebe uma fun√ß√£o callback que caso falhe, ele tenta executar novamente at√© um n√∫mero m√°ximo de tentativas ou at√© que a fun√ß√£o seja executada com sucesso.
https://www.npmjs.com/package/async-retry

```bash
npm install  async-retry@1.3.3
```

Criamos um arquivo orchestrator.js em "tests/orchestrator.js" para utilizar retry e garantir que vai estar tudo funcionando corretamente.

```javascript
import retry from "async-retry";

async function waitForAllServices() {
  await waitForWebServer();

  async function waitForWebServer() {
    return retry(fechStatusPage);

    async function fechStatusPage() {
      // Precisamos colocar alguma coisa que possa estourar um erro, para que o async retry fique tentando novamente
      // Caso n√£o ocorra erro ele vai entender que teve sucesso e continuar o script
      const response = await fetch("http://localhost:3000/api/v1/status");
      const responseBody = await response.json();
    }
  }
}

export default {
  waitForAllServices,
};
```

Agora somente importamos nosso orchestrator nos testes utilizando o hook beforeAll

```javascript
import orchestrator from "tests/orchestrator.js";

beforeAll(async () => {
  await orchestrator.waitForAllServices();
});
```

Mas ainda pode ocorrer de a m√°quina onde esses testes forem rodar ser muito lenta e acabar quebrando os testes, pois o jest por padr√£o espera somente 5 segundos para executar seus comandos, agora se o nosso servidor por algum motivo demorar mais que 5 segundo pra subir, o nosso hook beforeAll vai quebrar e o teste vai teste vai retornar um erro de timeout.

Podemos resolver esse problema adicionando mais tempo para o jest agurdar, fazemos isso no jest.config.js

```javascript
const jestConfig = createJestConfig({
  moduleDirectories: ["node_modules", "<rootDir>"],
  testEnvironment: "node",
  testTimeout: 60000,
});
```

# Aula 30

## rafaelcorrea-dev: "maxTimeout"

O jest por padr√£o utiliza um fator 2 para os retry (tentativas) do async-retry, ou seja, se a primeira tentativa falhar, ele espera 100ms para tentar novamente, se a segunda tentativa falhar, ele espera 200ms para tentar novamente, se a terceira tentativa falhar, ele espera 400ms para tentar novamente, e assim por diante.

Como isso pode atrasar e muito em determinados casos, podemos definir um tempo m√°ximo de espera entre as tentativas, para isso utilizamos o par√¢metro "maxTimeout" do async-retry.

## Configurar "Continuous Integration" (com GitHub Actions)

O que vamos fazer aqui √© o comando "npm test" rodar em uma m√°qui remota, sempre zerada.

Pra isso vamos utilizar o GutHubActions:
https://github.com/features/actions?locale=pt-BR

O Fluxo √© o seguinte:

- Tudo come√ßa com um Workflow (fluxo de trabalho)
- Dentro desse fluxo de trabalho definimos qual ser√° o evento que esse workflow vai ficar esperando acontecer (observando)
- Quando ocorrer esse evento ser√° executado um Job (tarefa) que precisa ser executado
- Precisamos definir qual vai ser o SO que ir√° rodar (RUNNER) as coisas
- Agora definido qual o SO podemos colocar qual ser√° os comandos que ir√£o rodar dentro dele (step-by-step)
  ![alt text](class-images/class-30/image.png)

Pra iniciar criamos o arquivo que vai ser nosso workflow de testes:
`.github/workflows/tests.yml`

podemos achar extens√µes para as Actions que ficam em:
https://github.com/marketplace

Aqui podemos achar por exemplo a extens√£o que estamos usando de `checkout`

Vamos utilizar o comando `npm ci` que √© mais indicado para ambientes de CI/CD, pois ele instala as depend√™ncias exatamente como est√£o definidas no package-lock.json, garantindo que o ambiente de desenvolvimento e o ambiente de CI/CD sejam id√™nticos.
Enquanto o `npm install` pode atualizar o package-lock.json se houver diferen√ßas, o `npm ci` sempre vai ser a mesma coisa
OBS: esta ai a importancia de sempre commitar o package-lock.json no reposit√≥rio.
![alt text](class-images/class-30/image-1.png)

O arquivo `tests.yml` ficou assim:

```yaml
# Definir o nome do fluxo
name: Automated Tests

# Definir qual evento ele deve ficar observando
on: pull_request

# Quando o Pull Request acontecer, precisar rodar os jobs
jobs:
  jest:
    name: Jest Ubuntu
    # Vamos definir aqui tamb√©m com o SO que vai rodar as coisas no runs-on
    runs-on: ubuntu-latest
    # Agora vamos definir os passos que o job vai executar
    steps:
      # Aqui usamos extens√µes (Actions) prontas do GitHub
      - uses: actions/checkout@v4 # Puxa o c√≥digo para dentro do ambiente

      - uses: actions/setup-node@v4 # Configura o Node.js
        with:
          node-version: "lts/hydrogen" # Vers√£o do Node.js

      # Aqui vamos executar comandos dentro do ambiente de forma manual
      - run: npm ci
      - run: npm test
```

Dessa forma j√° vai funcionar sempre fizer um Pull Request l√° no github, por√©m ainda temos um problema, porque mesmo que um teste falhe, ainda sim √© possivel fazer o merge com a main.

Para impedir isso √© preciso fazer algumas configura√ß√µes no github.

- Vamos em Settings e Branchs
  ![alt text](class-images/class-30/image-2.png)

Ai √© so adicionar as regras.
![alt text](class-images/class-30/image-3.png)

# Aula 31

## Lint Code: Style

Existem os Pr√© Formatadores e os P√≥s Formatadores.

Os `Pr√© Formatadores` s√£o aqueles que formatam o c√≥digo enquanto estamos escrevendo, como por exemplo o `Prettier`, que √© um formatador de c√≥digo que formata o c√≥digo automaticamente de acordo com as regras definidas.

Os `P√≥s Formatadores` s√£o aqueles que formatam o c√≥digo depois que salva o arquivo, como por exemplo o `ESLint`, que √© um linter que verifica o c√≥digo em busca de problemas de estilo e boas pr√°ticas, e pode ser configurado para corrigir automaticamente alguns desses problemas.

Os `P√≥s Formatadores` podedm ser divididos em duas categorias de especializa√ß√£o: Especializazdos em `Estiliza√ß√£o`do c√≥digo e especializado em `Qualidade`do c√≥digo.
![alt text](class-images/class-31/image.png)

Vamos criar um novo arquivo para o workflow de lint code:
`.github/workflows/linting.yml`

```yaml
name: Linting

on: pull_request

jobs:
  prettier:
    name: Prettier
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4 # Puxa o c√≥digo para dentro do ambiente

      - uses: actions/setup-node@v4 # Configura o Node.js
        with:
          node-version: "lts/hydrogen" # Vers√£o do Node.js

      - run: npm ci
      - run: npm run lint:prettier:check
```

L√° no github, precisamos adicioanr a regra de n√£o permitir fazer o merge enquanto a verifica√ß√£o do prettier n√£o estiver passando.
![alt text](class-images/class-31/image-1.png)

## Lint Code: Quality

Agora vamos trazer o ESLint para o projeto, para ele ajudar a manter algumas regras b√°sicas de qualidade de c√≥digo. Depois colocar isso no CI.
https://eslint.org/


Documenta√ß√£o para instalar o ESLint direto pelo NextJs, j√° com todas as recomenda√ß√µes prontas:
https://nextjs.org/docs/app/api-reference/config/eslint

A primeira coisa que fizemos foi criar um novo script no package.json para rodar o eslint:

```json
"scripts": {
  "lint:eslint:check": "next lint",
}
```

Quando rodei esse comando no terminal j√° me deu a op√ß√£o de instala√ß√£o.
![alt text](class-images/class-31/image-2.png)

Para que o ESLint consiga verificar todos os arquivos do projeto, podemos utilizar o proprio comando "eslint" ao inv√©s da abstra√ß√£o do next "next lint"

```json
"scripts": {
  "lint:eslint:check": "eslint .",
}
```
![alt text](class-images/class-31/image-3.png)

Agora precisamos fazer o ESLint entender como o Jest funciona, para que ele pare de reclarmar dos erross relacionados ao Jest, para isso instalamos o plugin do Jest para o ESLint:
https://www.npmjs.com/package/eslint-plugin-jest

```bash
npm i -D eslint-plugin-jest@28.6.0
```

Agora no .eslintrc.json adicionamos o plugin do jest e a configura√ß√£o recomendada dele:
{
  "extends": [
    "plugin:jest/recommended", -> essa √© a recomenda√ß√£o do plugin do jest para o eslint
    "eslint:recommended",
    "next/core-web-vitals"
  ]
}

Precisamos agora de um outro plugin para que as regras do prettier n√£o conflitem com as regras do eslint, para isso instalamos o eslint-config-prettier:
https://www.npmjs.com/package/eslint-config-prettier

Depois fazemos a instala√ß√£o:

```bash
npm i -D eslint-config-prettier@9.1.0
```

Por fim basta colocar o "prettier" no final do array de extends do .eslintrc.json, para que as regras do prettier sobrescrevam as regras do eslint.

```json
{
  "extends": [
    "plugin:jest/recommended",
    "eslint:recommended",
    "next/core-web-vitals",
    "prettier"
  ]
}
```

Para funcionar no CI, adicionamos essa nova informa√ß√£o no arquivo `.github/workflows/linting.yml`

```yaml
name: Linting

on: pull_request

jobs:
  prettier:
    name: Prettier
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4 # Puxa o c√≥digo para dentro do ambiente

      - uses: actions/setup-node@v4 # Configura o Node.js
        with:
          node-version: "lts/hydrogen" # Vers√£o do Node.js

      - run: npm ci
      - run: npm run lint:prettier:check
  eslint:
    name: Eslint
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4 # Puxa o c√≥digo para dentro do ambiente

      - uses: actions/setup-node@v4 # Configura o Node.js
        with:
          node-version: "lts/hydrogen" # Vers√£o do Node.js

      - run: npm ci
      - run: npm run lint:eslint:check

```

Nas `rulesets` do GitHub adicionamos essa nova regra do EsLint
![alt text](class-images/class-31/image-4.png)